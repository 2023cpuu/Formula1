import pandas as pd
import requests
from bs4 import BeautifulSoup
import time

def scrape_f1_races(year):
    url = f"https://www.formula1.com/en/results.html/{year}/races.html"
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")

    races = []
    table = soup.find("table", class_="resultsarchive-table")
    if table:
        rows = table.find_all("tr")[1:]  # Saltar encabezado
        for row in rows:
            cols = row.find_all("td")
            if len(cols) >= 5:
                races.append({
                    "Year": year,
                    "Grand Prix": cols[1].text.strip(),
                    "Date": cols[2].text.strip(),
                    "Winner": cols[3].text.strip(),
                    "Team": cols[4].text.strip()
                })
    return races

# Recolectar carreras de 1950 a 1959
all_races = []
for year in range(1950, 1960):
    print(f"Scrapeando {year}...")
    all_races.extend(scrape_f1_races(year))
    time.sleep(1)  # Espera para no sobrecargar el servidor

# Guardar en CSV
df = pd.DataFrame(all_races)
df.to_csv("F1_1950s_Race_Results_FULL.csv", index=False)
print("âœ… Archivo CSV guardado como F1_1950s_Race_Results_FULL.csv")
